name: Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

jobs:
  # ============================================================================
  # Testes UnitÃ¡rios (RÃ¡pidos)
  # ============================================================================
  unit-tests:
    name: Unit Tests
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: ['3.8', '3.9', '3.10', '3.11', '3.12']
        exclude:
          # Economiza recursos rodando apenas em ubuntu para versÃµes antigas
          - os: macos-latest
            python-version: '3.8'
          - os: windows-latest
            python-version: '3.8'

    steps:
      - name: ğŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4

      - name: ğŸ Configurar Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: ğŸ“¦ Instalar uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: ğŸ“¦ Instalar dependÃªncias
        run: |
          uv pip install --system -e ".[test]"

      - name: ğŸ§ª Executar testes unitÃ¡rios
        run: |
          pytest tests/unit -v \
            --cov=tools \
            --cov=ui \
            --cov-report=xml \
            --cov-report=term-missing \
            --junitxml=junit/test-results.xml

      - name: ğŸ“Š Upload coverage para Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-${{ matrix.os }}-py${{ matrix.python-version }}
          fail_ci_if_error: false

      - name: ğŸ“¤ Upload resultados de teste
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-unit-${{ matrix.os }}-py${{ matrix.python-version }}
          path: junit/test-results.xml

  # ============================================================================
  # Testes de IntegraÃ§Ã£o
  # ============================================================================
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']

    steps:
      - name: ğŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4

      - name: ğŸ Configurar Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: ğŸ“¦ Instalar uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: ğŸ“¦ Instalar dependÃªncias
        run: |
          uv pip install --system -e ".[test]"

      - name: ğŸ§ª Executar testes de integraÃ§Ã£o
        run: |
          pytest tests/integration -v \
            --cov=tools \
            --cov=ui \
            --cov-report=xml \
            --cov-report=term-missing \
            --junitxml=junit/test-results-integration.xml

      - name: ğŸ“Š Upload coverage para Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: integration
          name: codecov-integration-py${{ matrix.python-version }}
          fail_ci_if_error: false

      - name: ğŸ“¤ Upload resultados de teste
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-integration-py${{ matrix.python-version }}
          path: junit/test-results-integration.xml

  # ============================================================================
  # Testes Paralelos (Otimizado)
  # ============================================================================
  parallel-tests:
    name: Parallel Tests (Optimized)
    runs-on: ubuntu-latest
    needs: unit-tests

    steps:
      - name: ğŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4

      - name: ğŸ Configurar Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: ğŸ“¦ Instalar uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: ğŸ“¦ Instalar dependÃªncias
        run: |
          uv pip install --system -e ".[dev]"

      - name: ğŸš€ Executar testes paralelos otimizados
        run: |
          python tests/pytest_orchestration.py --mode optimized

      - name: ğŸ“Š Upload relatÃ³rios
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-reports-parallel
          path: |
            htmlcov/
            coverage.xml
            coverage.json

  # ============================================================================
  # Code Quality
  # ============================================================================
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4

      - name: ğŸ Configurar Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: ğŸ“¦ Instalar uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: ğŸ“¦ Instalar dependÃªncias
        run: |
          uv pip install --system -e ".[dev]"

      - name: ğŸ” Linting com Ruff
        run: |
          ruff check .

      - name: âœ¨ Verificar formataÃ§Ã£o com Black
        run: |
          black --check .

      - name: ğŸ” Type checking com MyPy
        run: |
          mypy tools ui || true

  # ============================================================================
  # Benchmark Performance
  # ============================================================================
  benchmark:
    name: Performance Benchmark
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'

    steps:
      - name: ğŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4

      - name: ğŸ Configurar Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: ğŸ“¦ Instalar uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: ğŸ“¦ Instalar dependÃªncias
        run: |
          uv pip install --system -e ".[dev]"

      - name: â±ï¸ Executar benchmarks
        run: |
          pytest tests -v -m benchmark --benchmark-only \
            --benchmark-json=benchmark.json || true

      - name: ğŸ“¤ Upload benchmark results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: benchmark-results
          path: benchmark.json

  # ============================================================================
  # Summary Report
  # ============================================================================
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, parallel-tests, code-quality]
    if: always()

    steps:
      - name: ğŸ“¥ Download all artifacts
        uses: actions/download-artifact@v4

      - name: ğŸ“Š Generate summary
        run: |
          echo "## ğŸ§ª Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Results:" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Unit Tests: ${{ needs.unit-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Integration Tests: ${{ needs.integration-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- ğŸš€ Parallel Tests: ${{ needs.parallel-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- ğŸ” Code Quality: ${{ needs.code-quality.result }}" >> $GITHUB_STEP_SUMMARY

      - name: âŒ Fail if any test failed
        if: |
          needs.unit-tests.result == 'failure' ||
          needs.integration-tests.result == 'failure' ||
          needs.parallel-tests.result == 'failure' ||
          needs.code-quality.result == 'failure'
        run: exit 1
